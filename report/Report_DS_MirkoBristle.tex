% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

\documentclass[letterpaper,twocolumn,11pt]{article}
\usepackage{usenix,epsfig,endnotes}
\usepackage{natbib}
\usepackage{amsmath}
\begin{document}



%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Multivariate Time Series Forecasting with Graph Neural Networks \\
 \Medium \it Data Science Seminar
}

\author{
{\rm Mirko Bristle, 14-109-576}\\
    University of Bern \\
    \\
    \today
}
\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
%\thispagestyle{empty}

%
%\subsection*{Abstract}
%Your Abstract Text Goes Here.  Just a few facts.
%Whet our appetites.

\section{Introduction}

Prediction of time series has a strong history with nevertheless current importance. With the rise of IoT devices, and a substancial
increase in information gathering in a wide variaty of domains the bases for the current state of the art time series forcasting was laid.
The applicability of time series prediction can be found in several domains such as finance, electricity markets, but also several fields in science [tbc].



This is citing \cite{wu2020connecting}


\section{Methodical Background}
The current report can be placed in the methodical perspective of time series forecasting while on the other hand using
taking advantage of the more recently developed toolbox of graph neural networks (GNN).
\subsection{Multivariate Time series forecasting (MTSF)}
Time series forecasting has a long history [tbc].

\textbf{ARIMA} ...

\textbf{RNN} ...

\textbf{LSTM}  ...

\subsection{Graph neural networks}

\section{MTGNN: Connecting the Dots}
In the paper of Wu et al. \cite{wu2020connecting} two major challenges concerning the combination of GNN and multivariate
time series forecasting are addressed.
The graph structure in MTSF represents the relation between the different temporal features.
A major issue is, that without prior knowledge, the relation between these features is unknown.
Further does the graph structure differ between different data sets, what makes it impossible to have a full end-to-end framework that adjusts to the properties of the graph.
The second challenge addresses the issue that a previously learned or explicitly supplied graph structure might not be optimal and thus,
should be updated during the learning process.
A step, most previously published GNNs leave a side, while focusing only on message passing.

\subsection{Formulating the Problem}
A $N$ dimensional multivariate timeseries consists of a serie of steps in time $z_t \in R^N$, with $z_t[i] \in R$
being the $i^{th}$ - variable at time step $t$. The obejctive is to predict either a Q-step-way value
$Y = \{z_{t_{P+Q}}\}$ or a sequence of M values $Y = \{z_{t_{P+1}}, z_{t_{P+2}},\dots,z_{t_{P+M}}\}$
from a past time series with $P$ steps $X = \{z_{t_{1}}, z_{t_{2}},\dots,z_{t_{P}}\}$.

The P past steps  $\Chi = {S_{t_1}, S_{t_2}, \dots, S_{t_P}}$ can be supplemented by $D$ auxiliary features s.d. the $i_{th}$-step
$S_{t_i} \in R^{1+D}$ has $z_t[i]$ as the first column, followed by the auxiliary features.

The objective is to minimize the loss of the the mapping $f: \chi \rightarrow Y$ with $l2$-regularization. [tbc]
\subsection{Architectual overview}
The authors propose three major components to address the challenges. To attack the first challenge a new graph learning layer
is introduced. The goal is to extract a first proposal of the interconnectedness of the features. The output of the model is a sparse adjacency matrix based on the supplied training data.
Based on the graph learning layer, the spacial dependencies among the features are learned in an graph convolution module to address the over-smoothing problem [describe -> directed graphs].
In the temporal convolution module the temporal patterns with different frequency and length should caught with a customized 1D convolution.

\subsection{Graph Learning Layer}
[x]
\subsection{Graph Concolution Module}
[x]
\subsection{Temporal Concolution Module}
[x]
\subsection{The learning Algorithm}
[x]
\section{Experimental evaluation}

\section{Replication Experiments}

\subsection{Method of replication}

\subsection{Results}

\section{Discussion}
\subsection{Integreation of Evaluation and Replication}
\subsection{Contribution to time series forecasting}
\subsection{Critique}
\subsection{Future research}

{\footnotesize \bibliographystyle{acm}
\bibliography{bibliography}}


\theendnotes

\end{document}







%A paragraph of text goes here.  Lots of text.  Plenty of interesting
%text. \\
%
%More fascinating text. Features\endnote{Remember to use endnotes, not footnotes!} galore, plethora of promises.\\
%
%\section{This is Another Section}
%
%Some embedded literal typset code might
%look like the following :
%
%{\tt \small
%\begin{verbatim}
%#include <iostream>
%using namespace std;
%main()
%{
%cout << "Hello world \n";
%return 0;
%}
%
%\end{verbatim}
%}
%
%Now we're going to cite somebody.  Watch for the cite tag.
%Here it comes~\cite{Einstein}.
%
%Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
%
%Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
%
%Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
%
%Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.







